{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25503c42",
   "metadata": {},
   "source": [
    "Stuff about making sure u run stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import pyrender\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def colorize(\n",
    "    depth: np.ndarray,\n",
    "    mask: np.ndarray = None,\n",
    "    normalize: bool = True,\n",
    "    cmap: str = \"Spectral\",\n",
    ") -> np.ndarray:\n",
    "    if mask is None:\n",
    "        depth = np.where(depth > 0, depth, np.nan)\n",
    "    else:\n",
    "        depth = np.where((depth > 0) & mask, depth, np.nan)\n",
    "    disp = 1 / depth\n",
    "    if normalize:\n",
    "        min_disp, max_disp = np.nanquantile(disp, 0.001), np.nanquantile(disp, 0.999)\n",
    "        disp = (disp - min_disp) / (max_disp - min_disp)\n",
    "    colored = np.nan_to_num(matplotlib.colormaps[cmap](1.0 - disp), 0)\n",
    "    colored = (colored.clip(0, 1) * 255).astype(np.uint8)[:, :, :3]\n",
    "    return colored\n",
    "\n",
    "def fill_holes(image, depth, max_hole_size=30, window_size=5):\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    \n",
    "    valid_mask = depth > 0\n",
    "    if np.all(valid_mask):\n",
    "        return image\n",
    "    \n",
    "    filled_image = image.copy()\n",
    "    working_mask = valid_mask.copy()\n",
    "    \n",
    "    mask_uint8 = valid_mask.astype(np.uint8) * 255\n",
    "    \n",
    "    # Create a distance transform map\n",
    "    # The distance transform will help us find the holes\n",
    "    dist_map = cv2.distanceTransform(255 - mask_uint8, cv2.DIST_L2, 5)\n",
    "    holes_to_fill = (dist_map < max_hole_size) & (~valid_mask)\n",
    "    \n",
    "    if not np.any(holes_to_fill):\n",
    "        return filled_image\n",
    "    \n",
    "    half_window = window_size // 2\n",
    "    \n",
    "    for dist in range(1, max_hole_size + 1):\n",
    "        current_level = (dist_map >= dist-1) & (dist_map < dist) & holes_to_fill\n",
    "        \n",
    "        if not np.any(current_level):\n",
    "            continue\n",
    "        \n",
    "        # For each hole pixel at this distance level\n",
    "        for y, x in zip(*np.where(current_level)):\n",
    "            # Define neighborhood\n",
    "            y_min, y_max = max(0, y-half_window), min(image.shape[0], y+half_window+1)\n",
    "            x_min, x_max = max(0, x-half_window), min(image.shape[1], x+half_window+1)\n",
    "            \n",
    "            neighborhood_mask = working_mask[y_min:y_max, x_min:x_max]\n",
    "            \n",
    "            if np.any(neighborhood_mask):\n",
    "                neighborhood = filled_image[y_min:y_max, x_min:x_max]\n",
    "                \n",
    "                # Calculate average of valid pixels for each channel\n",
    "                valid_pixels = neighborhood[neighborhood_mask]\n",
    "                if len(valid_pixels) > 0:\n",
    "                    # Average valid neighbors - ignores invalid pixels completely\n",
    "                    avg_value = np.mean(valid_pixels, axis=0)\n",
    "                    filled_image[y, x] = avg_value\n",
    "                \n",
    "                # Update working mask to mark this pixel as valid for next iteration\n",
    "                working_mask[y, x] = True\n",
    "    \n",
    "    return filled_image\n",
    "\n",
    "def pose_align(pose):\n",
    "    matrix = np.identity(4)\n",
    "    matrix[1, 1] = -1\n",
    "    matrix[2, 2] = -1\n",
    "    opengl_conversion_matrix = matrix\n",
    "    align_rotation = np.eye(4)\n",
    "    align_rotation[:3, :3] = Rotation.from_euler(\n",
    "        \"x\", 180, degrees=True\n",
    "    ).as_matrix()\n",
    "    pose_aligned = (pose @ opengl_conversion_matrix)\n",
    "    # pose_aligned = (pose @ opengl_conversion_matrix @ align_rotation)\n",
    "    return pose_aligned\n",
    "\n",
    "def render_to_image(pts3d, images, masks_conf=None, camera_pose=None, focal_length=None, height=None, width=None, point_size=3.0):\n",
    "    H, W = images.shape[1:3]\n",
    "\n",
    "    if height is None:\n",
    "        height = H\n",
    "    if width is None:\n",
    "        width = W\n",
    "\n",
    "    if height is not None and width == -1:\n",
    "        width = int(height * W / H)\n",
    "    if width is not None and height == -1:\n",
    "        height = int(width * H / W)\n",
    "    \n",
    "    scene = pyrender.Scene(bg_color=(0, 0, 0))\n",
    "    pc = pts3d.reshape(-1, 3)\n",
    "    clr = images.reshape(-1, 3)\n",
    "    if masks_conf is not None:\n",
    "        mask = masks_conf.reshape(-1)\n",
    "        pc = pc[mask.astype(bool)]\n",
    "        clr = clr[mask.astype(bool)]\n",
    "\n",
    "    cloud = pyrender.Mesh.from_points(pc, colors=clr)\n",
    "    scene.add(cloud)\n",
    "    \n",
    "    if camera_pose is not None and focal_length is not None:\n",
    "        camera_pose = pose_align(camera_pose)\n",
    "\n",
    "        # Convert focal length to field of view\n",
    "        fov = 2 * np.arctan(H / (2 * focal_length))\n",
    "        camera = pyrender.PerspectiveCamera(yfov=fov, aspectRatio=width/height)\n",
    "    else:\n",
    "        camera = pyrender.PerspectiveCamera(yfov=np.pi/3.0, aspectRatio=width/height)\n",
    "        camera_pose = np.eye(4)\n",
    "        camera_pose[2, 3] = 2.0\n",
    "    \n",
    "    scene.add(camera, pose=camera_pose)\n",
    "    \n",
    "    r = pyrender.OffscreenRenderer(width, height, point_size=3.0)\n",
    "    color, depth = r.render(scene, flags=pyrender.constants.RenderFlags.FLAT)\n",
    "    \n",
    "    return color, depth\n",
    "\n",
    "def to_focal(focal, new_focal, pose, strength=1.0):\n",
    "    forward = pose[:3, 2]\n",
    "\n",
    "    forward = forward / np.linalg.norm(forward)\n",
    "\n",
    "    diff = new_focal - focal\n",
    "\n",
    "    ratio = diff / focal * strength\n",
    "\n",
    "    new_pose = pose.copy()\n",
    "    new_pose[:3, 3] -= forward * ratio\n",
    "\n",
    "    return new_pose\n",
    "\n",
    "\n",
    "def circleOfConfusion(focal_length, aperture_size, focal_distance, depth):\n",
    "    # Circle of confusion formula\n",
    "    return np.abs(\n",
    "        aperture_size\n",
    "        * ((depth - focal_distance) / focal_distance)\n",
    "        * (focal_length / (focal_distance - focal_length))\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_depth_of_field(\n",
    "    image, depth_map, focal_length, focus_distance=None, aperture_size=10\n",
    "):\n",
    "    if focus_distance is None:\n",
    "        focus_distance = np.mean(depth_map)\n",
    "\n",
    "    focal_length /= 1000.0  # Convert to mm\n",
    "\n",
    "    # Calculate circle of confusion for each pixel\n",
    "    coc_map = circleOfConfusion(focal_length, aperture_size, focus_distance, depth_map)\n",
    "\n",
    "    # Define discrete blur levels (kernel sizes)\n",
    "    blur_levels = [1, 3, 7, 15, 31, 63]  # Kernel sizes must be odd\n",
    "\n",
    "    # Create blurred versions of the image at different levels\n",
    "    blurred_images = []\n",
    "    for kernel_size in blur_levels:\n",
    "        if kernel_size == 1:  # No blur\n",
    "            blurred_images.append(image)\n",
    "        else:\n",
    "            blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "            blurred_images.append(blurred)\n",
    "\n",
    "    # Convert CoC to kernel size\n",
    "    kernel_sizes = 2 * coc_map + 1\n",
    "\n",
    "    # Create the result image\n",
    "    result = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "    # For each blur level pair\n",
    "    for i in range(len(blur_levels) - 1):\n",
    "        lower_size = blur_levels[i]\n",
    "        upper_size = blur_levels[i + 1]\n",
    "\n",
    "        # Find pixels with kernel sizes in this range\n",
    "        mask = (kernel_sizes >= lower_size) & (kernel_sizes < upper_size)\n",
    "\n",
    "        if np.any(mask):\n",
    "            # Calculate interpolation weights\n",
    "            alpha = (kernel_sizes - lower_size) / (upper_size - lower_size)\n",
    "            alpha = np.clip(alpha, 0, 1)\n",
    "\n",
    "            # Ensure mask and alpha have compatible dimensions with image\n",
    "            if mask.ndim == 2 and image.ndim == 3:\n",
    "                mask = mask[..., np.newaxis]\n",
    "            if alpha.ndim == 2 and image.ndim == 3:\n",
    "                alpha = alpha[..., np.newaxis]\n",
    "\n",
    "            # Interpolate between the two blur levels\n",
    "            interpolated = (1 - alpha) * blurred_images[i] + alpha * blurred_images[\n",
    "                i + 1\n",
    "            ]\n",
    "\n",
    "            # Add to result\n",
    "            result += mask * interpolated\n",
    "\n",
    "    # Handle pixels with kernel size >= the maximum blur level\n",
    "    mask = kernel_sizes >= blur_levels[-1]\n",
    "    if mask.ndim == 2 and image.ndim == 3:\n",
    "        mask = mask[..., np.newaxis]\n",
    "    result += mask * blurred_images[-1]\n",
    "\n",
    "    return result.astype(image.dtype), coc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data_path = \"out/test\".rstrip(\"/\")\n",
    "\n",
    "npz_file = np.load(os.path.join(data_path, f\"{os.path.basename(data_path)}.npz\"))\n",
    "\n",
    "images = npz_file[\"images\"]\n",
    "pts3d = npz_file[\"pts3d\"]\n",
    "masks_conf = npz_file[\"masks_conf\"]\n",
    "focals = npz_file[\"focals\"]\n",
    "poses = npz_file[\"pred_poses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2edf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = focals[0] * 0.7\n",
    "\n",
    "camera_pose = to_focal(focals[0], focal_length, poses[0], strength=1.3)\n",
    "\n",
    "color, depth = render_to_image(\n",
    "    pts3d, images, camera_pose=camera_pose, focal_length=focal_length, height=720, width=-1\n",
    ")\n",
    "\n",
    "H, W = color.shape[:2]\n",
    "focal_distance = depth[int(H * 0.43), W // 3]\n",
    "\n",
    "out, coc = apply_depth_of_field(\n",
    "    color, depth, focal_length, focus_distance=focal_distance, aperture_size=8\n",
    ")\n",
    "\n",
    "display(\n",
    "    Image.fromarray(\n",
    "        np.vstack(\n",
    "            (\n",
    "                np.hstack((fill_holes(color, depth), colorize(depth))),\n",
    "                np.hstack((out, colorize(coc))),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
